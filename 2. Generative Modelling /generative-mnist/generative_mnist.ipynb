{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian generative models for handwritten digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the 1-NN classifier yielded a 3.09% test error rate on the MNIST data set of handwritten digits. We will now see that a Gaussian generative model does almost as well, while being significantly faster and more compact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up notebook and load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by importing the required packages and data. For this notebook we will be using the *entire* `MNIST` dataset. The code below defines some helper functions that will load `MNIST` onto your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import gzip, os , sys\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **displaychar** shows a single MNIST digit. To do this, it first has to reshape the 784-dimensional vector into a 28x28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaychar(image):\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displaychar(train_data[58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set consists of 60,000 images. Thus `train_data` should be a 60000x784 array while `train_labels` should be 60000x1. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"magenta\">For you to do:</font>** Define a function, **fit_generative_model**, that takes as input a training set (data `x` and labels `y`) and fits a Gaussian generative model to it. It should return the parameters of this generative model; for each label `j = 0,1,...,9`, we have:\n",
    "* `pi[j]`: the frequency of that label\n",
    "* `mu[j]`: the 784-dimensional mean vector\n",
    "* `sigma[j]`: the 784x784 covariance matrix\n",
    "\n",
    "This means that `pi` is 10x1, `mu` is 10x784, and `sigma` is 10x784x784.\n",
    "\n",
    "We have already seen how to fit a Gaussian generative model in the Winery example, but now there is an added ingredient. <font color=\"magenta\">The empirical covariances are very likely to be singular (or close to singular), which means that we won't be able to do calculations with them</font>. Thus it is important to **regularize** these matrices. The standard way of doing this is to add `cI` to them, where `c` is some constant and `I` is the 784-dimensional identity matrix. (To put it another way, we compute the empirical covariances and then increase their diagonal entries by some constant `c`.)\n",
    "\n",
    "This modification is guaranteed to yield covariance matrices that are non-singular, for any `c > 0`, no matter how small. But this doesn't mean that we should make `c` as small as possible. Indeed, `c` is now a parameter, and by setting it appropriately, we can improve the performance of the model. We will study **regularization** in greater detail over the coming weeks.\n",
    "\n",
    "Your routine needs to choose a good setting of `c`. Crucially, this needs to be done using the training set alone. So you might try setting aside part of the training set as a validation set, or using some kind of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generative_model(x,y):\n",
    "    k = 10  # labels 0,1,...,k-1\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    for label in range(0,k):\n",
    "        indices= (y==label)\n",
    "        mu[label]= np.mean(x[indices,:],axis=0)\n",
    "        sigma[label]= np.cov(x[indices,:], rowvar=0, bias=1) + 1000*np.eye(784) #Regularized\n",
    "        pi[label]= float(sum(indices))/float(len(y))\n",
    "        \n",
    "    # Halt and return parameters\n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's try out your function. In particular, we will use **displaychar** to visualize the means of the Gaussians for the first three digits. You can try the other digits on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu, sigma, pi = fit_generative_model(train_data, train_labels)\n",
    "displaychar(mu[0])\n",
    "displaychar(mu[1])\n",
    "displaychar(mu[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many errors your model makes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model makes 489 errors out of 10000\n"
     ]
    }
   ],
   "source": [
    "# Compute log Pr(label|image) for each [test image,label] pair.\n",
    "k = 10  # labels 0,1,...,k-1\n",
    "score = np.zeros((len(test_labels),k))\n",
    "for label in range(0,k):\n",
    "    rv = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "    for i in range(0,len(test_labels)):\n",
    "       score[i,label] = np.log(pi[label]) + rv.logpdf(test_data[i,:])\n",
    "predictions = np.argmax(score, axis=1)\n",
    "# Finally, tally up score\n",
    "errors = np.sum(predictions != test_labels)\n",
    "print(\"Your model makes \" + str(errors) + \" errors out of 10000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You will need to answer variants of these questions as part of this week's assignment*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 1:</font> What happens if you do not regularize the covariance matrices? --> Shows Linalg Error : singular matrix, because of sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 2:</font> What happens if you set the value of `c` too high, for instance to one billion? Do you understand why this happens? --> Test error approaches that of a random classifier generating 7929 errors whatever value you take for c. It's no more a normal distribution but a flat distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 3:</font> What value of c did you end up using? How many errors did your model make on the training set? c=1000, 489 errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">If you have the time</font>: We have talked about using the same regularization constant `c` for all ten classes. What about using a different value of `c` for each class? How would you go about choosing these? Can you get better performance in this way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model makes 4120 errors out of 10000\n"
     ]
    }
   ],
   "source": [
    "def fit_generative_model(x,y):\n",
    "    k = 10  # labels 0,1,...,k-1\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    for label in range(0,k):\n",
    "        indices= (y==label)\n",
    "        mu[label]= np.mean(x[indices,:],axis=0)\n",
    "        sigma[label]= np.cov(x[indices,:], rowvar=0, bias=1) + np.random.randint(1000,4000)*np.eye(784) #Regularized /\n",
    "        #with random c values for different classes. Check using commands : for i in range(k): print(sigma[i]).\n",
    "        pi[label]= float(sum(indices))/float(len(y))\n",
    "        \n",
    "    # Halt and return parameters\n",
    "    return mu, sigma, pi\n",
    "\n",
    "mu, sigma, pi = fit_generative_model(train_data, train_labels)\n",
    "\n",
    "# Compute log Pr(label|image) for each [test image,label] pair.\n",
    "k = 10  # labels 0,1,...,k-1\n",
    "score = np.zeros((len(test_labels),k))\n",
    "for label in range(0,k):\n",
    "    rv = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "    for i in range(0,len(test_labels)):\n",
    "       score[i,label] = np.log(pi[label]) + rv.logpdf(test_data[i,:])\n",
    "predictions = np.argmax(score, axis=1)\n",
    "# Finally, tally up score\n",
    "errors = np.sum(predictions != test_labels)\n",
    "print(\"Your model makes \" + str(errors) + \" errors out of 10000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No, we won't get a better performance this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
